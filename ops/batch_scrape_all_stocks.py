import requests
import pandas as pd
import time
import traceback
from scrape_es_bulk_final import scrape_to_bulk_json

def fetch_stock_json(url):
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": "http://www.cninfo.com.cn/"
    }
    print(f"ğŸŒ è¯·æ±‚: {url}")
    resp = requests.get(url, headers=headers, timeout=15)
    resp.raise_for_status()
    try:
        data = resp.json()
        if isinstance(data, dict) and "stockList" in data:
            return data["stockList"]
        return data
    except Exception as e:
        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
        return []

def load_all_stocks():
    print("ğŸ“¥ æ­£åœ¨ä¸‹è½½å…¨é‡ A è‚¡å…¬å¸åˆ—è¡¨...")
    sz_list = fetch_stock_json("http://www.cninfo.com.cn/new/data/szse_stock.json")
#     sh_list = fetch_stock_json("http://www.cninfo.com.cn/new/data/shse_stock.json")

#     all_list = sz_list + sh_list
    df = pd.DataFrame(sz_list)
    df = df[df["category"] == "Aè‚¡"]  # ä»… A è‚¡
    df = df[["code", "zwjc", "orgId"]].drop_duplicates()
    print(f"âœ… è·å–åˆ° A è‚¡å…¬å¸å…±è®¡: {len(df)} å®¶")
    return df

def batch_scrape():
    df = load_all_stocks()
    failed = []

    for idx, row in df.iterrows():
        code = row["code"]
        name = row["zwjc"]
        org_id = row["orgId"]

        print(f"\nğŸš€ æ­£åœ¨æŠ“å–: {code} {name}")
        try:
            scrape_to_bulk_json(stock_code=code, stock_name=name, org_id=org_id)
            time.sleep(1.5)  # é˜²æ­¢è¿‡å¿«è§¦å‘é™æµ
        except Exception:
            print(f"âŒ æŠ“å–å¤±è´¥: {code} {name}")
            print(traceback.format_exc())
            failed.append({"code": code, "name": name})

    if failed:
        print(f"\nâš ï¸ æŠ“å–å¤±è´¥ {len(failed)} é¡¹:")
        for item in failed:
            print(f"- {item['code']} {item['name']}")
    else:
        print("\nâœ… å…¨éƒ¨å…¬å¸æŠ“å–å®Œæˆï¼")

if __name__ == "__main__":
    batch_scrape()
